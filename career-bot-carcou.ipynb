{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Carcou, Your Personalised Career Bot\n\nbrought to you by `Shami THIRION SEN`\n\n---\n\nWe know how grueling a job hunt can be! Work is not only the means of earning our living, but most importantly, it is a way of unleashing our inner talents.\n\nWorry no more! Your virtual counsellor is at your service to guide you through this process, whether you‚Äôre a newbie trying to make your way into the job market, or an experienced professional looking to expand your horizons! We have got you covered!","metadata":{}},{"cell_type":"markdown","source":"---\n\n### üß† Agentic AI\n\nWelcome to our **Agentic AI** showcase!  \nThis project features a **virtual counselor** designed to interact with users, gather relevant information, and fetch contextually useful answers from the internet üåê.\n\nIt demonstrates our ability to build intelligent, interactive, and autonomous AI experiences.\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n### üì¶ Installing the Libraries\n\nLet‚Äôs get the formalities out of the way üõ†Ô∏è  \nIn this section, we‚Äôll **install the necessary dependencies and the google API Key** (and clean out any that aren‚Äôt needed).\n\nAdditional libraries will be imported as we move through the notebook and explore different sections. Stay tuned üìö\n\n---\n","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp 2>/dev/null  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n!pip uninstall -y async-timeout # Uninstall the conflicting version of async-timeout\n!pip install \"async-timeout>=4.0.0,<5.0.0\" # Install a compatible version of async-timeout within the required range\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai # Removing potentially conflicting packages\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7' # Install langgraph and related packages\n\nfrom google import genai\nfrom google.genai import types\nimport os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:42:09.992927Z","iopub.execute_input":"2025-04-20T15:42:09.993395Z","iopub.status.idle":"2025-04-20T15:43:24.635262Z","shell.execute_reply.started":"2025-04-20T15:42:09.993370Z","shell.execute_reply":"2025-04-20T15:43:24.633952Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Skipping async-timeout as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting async-timeout<5.0.0,>=4.0.0\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nInstalling collected packages: async-timeout\nSuccessfully installed async-timeout-4.0.3\n\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m941.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-gbq 0.26.1 requires google-cloud-bigquery<4.0.0dev,>=3.4.2, which is not installed.\nbigframes 1.36.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.18.0, which is not installed.\ngoogle-cloud-aiplatform 1.79.0 requires google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0, which is not installed.\nopentelemetry-proto 1.32.1 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n\n### üîÅ Adding Retry Logic\n\nTo make our AI agent more **robust and reliable**, we add a retry mechanism to handle occasional API hiccups (like rate limits or temporary outages).\n\nUsing `google.api_core.retry`, we wrap the `generate_content` function so that it **automatically retries** when specific error codes (`429`, `503`) are encountered.\n\nThis helps avoid crashes during high-traffic times or flaky network issues üö¶\n\n---\n","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:24.636820Z","iopub.execute_input":"2025-04-20T15:43:24.637364Z","iopub.status.idle":"2025-04-20T15:43:24.844044Z","shell.execute_reply.started":"2025-04-20T15:43:24.637332Z","shell.execute_reply":"2025-04-20T15:43:24.843212Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"---\n\n### ü§ñ Creating the Chat Agent\n\nTime to build our **virtual career counsellor**, `CarCou` ‚Äî a smart, structured, and encouraging AI designed to help users explore and grow their careers üå±.\n\n#### üß± State Definition\n\nWe define a `SearchState` to manage the conversation:\n- `messages`: Tracks the ongoing dialogue, updated via `add_messages`\n- `finished`: A flag indicating if the user's journey is complete\n\nThis setup ensures that our chatbot can **retain conversation context** across each interaction.\n\n#### üß† System Instructions\n\nWe provide CarCou with clear behavioral guidelines:\n- Start by introducing itself\n- Collect user info step-by-step: name, education, experience level, goals\n- Ask clarifying questions if needed\n- Suggest 3 job roles tailored to the user\n- Offer to generate a r√©sum√© and cover letter (in Markdown) ‚ú®\n- End politely if the user types `q` or `exit`\n\n> üí¨ All messages are designed to be concise, well-structured, and easy to follow.\n\n#### üëã Welcome Message\n\nThe chat begins with an inviting prompt that asks the user about their intent:\n```text\nWelcome! I am CarCou, your virtual Career Counsellor...\n","metadata":{}},{"cell_type":"code","source":"# Creating Chat Agent\n\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph.message import add_messages\n\n# State is a Dict with messages, conversation status, finished keys\nclass SearchState(TypedDict):\n    \"\"\"State representing the conversation status.\"\"\"\n\n    # The chat conversation. Preserves the conversation history between nodes. \n    # The `add_messages` annotation indicates to LangGraph that state is updated by appending returned messages, not replacing them.\n    messages: Annotated[list, add_messages]    \n    finished: bool # Flag indicating that the order is placed and completed.\n\n\n# System instruction defining how the chatbot is expected to behave (rules, functions and tones)\nCAREERCOUNSELLORBOT_SYSINT = (\n    \"system\",  # 'system' indicates the message is a system instruction.\n    \"You are a Career Counsellor Bot named CarCou, an interactive all comprehensive career counsellor facilitating professional evolution of beginner to advanced job seekers and help keep morales high.\"\n    \"Always present the information in a structured manner, enumerate when suitable. Don't display long lines of text. 10 words are ideal.\"\n    \"First present yourself as CarCou a reliable career counsellor here to help the person get their dream job.\"\n    \"Then ask the user about themselves: their name, current degrees, professional interests (particular sector), and their experience level, beginner : entering the job market, experienced : looking for a change, established: looking to further career prospects. Ask the questions one by one.\"\n    \"Ask clarifying questions if any of the answers are vague or don't provide precise information.\"\n    \"Ask for all the information one by one, memorise them and confirm the information at the end.\"\n    \"Suggest 3 most suitable jobs for the person. Call store_jobs to store the 3 jobs you suggest as string values, in this way store_jobs(job1, job2, job3).\"\n    \"Ask them which one is their favourite option. And ask them if they would live help with a tailored r√©sume.If the user says yes, generate a cv for that position in a markdown format based on the information collected. Else skip to the next question.\"\n    \"Then ask if they need help with a cover letter. If they say yes, ask for more details like name, surname and address and please generate a letter in a markdown format.\"\n    \"Else say thank you and ask them to continue down the page to get more valuable information, exit the chat.\"\n    \"If at any point the user types 'q' or 'exit', end the chat\",\n)\n\n# This is the message with which the system opens the conversation.\nWELCOME_MSG = \"Welcome ! I am CarCou your virtual Career Counsellor. I am here to help you unlock your potentials. Are you here today : i) for a job hunt ii)to improve your current prospects eg. salary or change of position ? iii) Please Type `q` to quit.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:24.844923Z","iopub.execute_input":"2025-04-20T15:43:24.845338Z","iopub.status.idle":"2025-04-20T15:43:25.617938Z","shell.execute_reply.started":"2025-04-20T15:43:24.845315Z","shell.execute_reply":"2025-04-20T15:43:25.616442Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"---\n\n### Defining the Chatbot Logic\n\nWe now define **CarCou's conversational flow** by combining the power of **LangGraph** and **Gemini 2.0 Flash** ‚ú®.\n\n#### ‚öôÔ∏è Language Model Setup\n\nWe initialize the chatbot using:\n\n```python\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n```\n\nThis allows us to invoke messages with Google's lightweight yet powerful language model.\n\n---\n\n#### üí¨ Chatbot Function\n\nThe `chatbot()` function acts as a **wrapper** around the language model's chat interface:\n- It maintains message history\n- It includes the system prompt to guide tone & logic\n- It returns the model's response as an updated state\n\n---\n\n#### üë§ Human Interaction Node\n\nThe `human_node()` handles:\n- Displaying the last message from the bot\n- Capturing the user's input\n- Flagging when the user chooses to exit (e.g., typing `q`, `exit`, or just pressing Enter)\n\nThis function keeps the interaction simple and intuitive.\n\n---\n\n#### üëã Chatbot with a Friendly Welcome\n\nThe `chatbot_with_welcome_msg()` function starts the chat gracefully:\n- If no messages are present, it sends the `WELCOME_MSG`\n- Otherwise, it proceeds with the conversation\n\n> ü™Ñ This gives users a smooth, welcoming first impression while keeping responses structured.\n\n---\n\n#### üîÅ Routing the Flow\n\nFinally, `maybe_exit_human_node()` decides whether the chat should continue or end:\n- If the conversation is marked as `finished`, we route to `END`\n- Otherwise, we loop back to the chatbot\n\nThis setup helps CarCou gracefully end sessions when needed üíº\n\n---\n","metadata":{}},{"cell_type":"code","source":"## Defining Chatbot\n\nfrom langgraph.graph import StateGraph, START, END\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom IPython.display import Image, display\nfrom langchain_core.messages.ai import AIMessage\nfrom typing import Literal\n\n\n\n# Picking gemini 2.0 flash model\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n\ndef chatbot(state: SearchState) -> SearchState:\n    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n    message_history = [CAREERCOUNSELLORBOT_SYSINT] + state[\"messages\"]\n    return {\"messages\": [llm.invoke(message_history)]}\n\n## Defining the human node\ndef human_node(state: SearchState) -> SearchState:\n    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n    last_msg = state[\"messages\"][-1]\n    print(\"Model:\", last_msg.content)\n    user_input = input(\"User: \")\n    # If it looks like the user is trying to quit, flag the conversation as over.\n    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\", \"\"}:\n        state[\"finished\"] = True # state is a dict\n\n    return state | {\"messages\": [(\"user\", user_input)]}\n\n\ndef chatbot_with_welcome_msg(state: SearchState) -> SearchState:\n    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n    if state[\"messages\"]:\n        # If there are messages, continue the conversation with the Gemini model.\n        new_output = llm.invoke([CAREERCOUNSELLORBOT_SYSINT] + state[\"messages\"])\n    else:        \n        new_output = AIMessage(content=WELCOME_MSG)# If there are no messages, start with the welcome message.\n\n    return state | {\"messages\": [new_output]}\n\n\n\ndef maybe_exit_human_node(state: SearchState) -> Literal[\"chatbot\", \"__end__\"]:\n    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n    if state.get(\"finished\", False):\n        return END\n    else:\n        return \"chatbot\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:25.620843Z","iopub.execute_input":"2025-04-20T15:43:25.621142Z","iopub.status.idle":"2025-04-20T15:43:26.445416Z","shell.execute_reply.started":"2025-04-20T15:43:25.621119Z","shell.execute_reply":"2025-04-20T15:43:26.444131Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"---\n\n### üõ†Ô∏è Defining Tools for Agentic AI\n\nA key aspect of **Agentic AI** is its ability to **autonomously call tools** when needed ‚Äî without explicit user instructions.\n\nIn our setup, the chatbot can automatically trigger internal tools like `store_jobs()` whenever it decides the time is right (e.g., after generating tailored job suggestions) üîÑ\n\nThis empowers the agent to:\n- Take initiative based on conversation context\n- Manage state (like storing job options)\n- Chain together smart actions without manual steps üß†‚öôÔ∏è\n\n---\n\n#### üß∞ Example: Job Storage Tool\n\nWe define a simple tool that stores up to three job titles suggested by the model:\n\n```python\n@tool\ndef store_jobs(*jobs: Optional[str]) -> list:\n    \"\"\"Stores between 1 and 3 job titles provided by the model in a python list format.\n    \n    Returns:\n      A list of up to three jobs considered suitable by the career bot.\n    \"\"\"\n```\n\nThis tool can then be **invoked automatically by the model** at the right point in the conversation, showcasing the autonomous and agentic nature of CarCou üíº‚ú®\n\n---\n","metadata":{}},{"cell_type":"code","source":"# Defining a tool\nfrom langchain_core.tools import tool\nfrom google.genai import types\nfrom typing import Optional\n\n\n@tool\ndef store_jobs(*jobs: Optional[str]) -> list:\n    \"\"\"Stores between 1 and 3 job titles provided by the model in a python list format.\n    \n    Returns:\n      A list of upto three jobs considered suitable by the career bot.\n    \"\"\"\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:26.446695Z","iopub.execute_input":"2025-04-20T15:43:26.447019Z","iopub.status.idle":"2025-04-20T15:43:26.457003Z","shell.execute_reply.started":"2025-04-20T15:43:26.446983Z","shell.execute_reply":"2025-04-20T15:43:26.455961Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"---\n\n### üõ†Ô∏è Adding the Tool Node\n\nIn Agentic AI, **tool nodes** allow the chatbot to **automatically execute specific functions** based on the context of the conversation. This provides a high degree of **autonomy** to the chatbot, enabling it to take actions without needing explicit user requests.\n\n#### üîß Tool Node Setup\n\nWe create a `ToolNode` to handle the execution of tools like `store_jobs`, which can be invoked by the chatbot when necessary:\n\nThis allows the chatbot to call the `store_jobs` tool during the conversation when needed.\n\n---\n\n#### üîÑ Routing Between Tool & Human Nodes\n\nThe function `maybe_route_to_tools()` ensures that the conversation **routes dynamically**:\n- If the chatbot needs to call a tool (like storing job titles), the flow will route to the **\"tools\" node**.\n- If the chatbot is waiting for user input, it will route to the **\"human\" node**.\n\nThis provides a **flexible and dynamic flow**, allowing the chatbot to shift gears seamlessly between human interaction and tool execution üîÑ\n\n---\n\n#### üß† Chatbot with Tools\n\nNow, the `chatbot_with_tools()` function integrates tools into the chatbot‚Äôs conversation:\n- If tool calls are required (e.g., storing job suggestions), they will be automatically invoked and handled.\n- The chatbot will continue the conversation naturally, with the tools working in the background to support it.\n\n---\n\n#### üñºÔ∏è Visualizing the Chatbot Flow\n\nFinally, we **visualize the graph** to understand the structure of the chatbot's decision-making process:\n\nThis visual representation helps us see how the chatbot interacts with users, invokes tools, and returns to human input seamlessly üé®\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"# Adding the tool node\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import ToolNode\nfrom langchain_core.messages import ToolMessage\n\n\n# --- Tool Node ---\ntools = [store_jobs]\ntool_node = ToolNode(tools)\nllm_with_tools = llm.bind_tools(tools)\n\n## To execute tool node\ndef maybe_route_to_tools(state: SearchState) -> Literal[\"tools\", \"human\"]:\n    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found when parsing state: {state}\")\n\n    # Only route based on the last message.\n    msg = msgs[-1]\n\n    # When the chatbot returns tool_calls, route to the \"tools\" node.\n    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        for tool_call in msg.tool_calls:\n            if tool_call[\"name\"] == \"store_jobs\":\n                ## storing the jobs in a global variable for later use##\n                global job_list\n                job_list = []\n                job_list.extend(msg.tool_calls[0]['args']['jobs'])\n                # print(\"Storing the list of Jobs\", job_list)   # intermediary step to check if the tool is being called    \n            \n            return \"tools\"\n    else:\n        return \"human\"\n\n\n\ndef chatbot_with_tools(state: SearchState) -> SearchState:\n    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n    defaults = {\"jobs\": [], \"finished\": False}\n\n    if state[\"messages\"]:\n        new_output = llm_with_tools.invoke([CAREERCOUNSELLORBOT_SYSINT] + state[\"messages\"])\n    else:\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    # Set up some defaults if not already set, then pass through the provided state,\n    # overriding only the \"messages\" field.\n    return defaults | state | {\"messages\": [new_output]}\n\n\n\"\"\" Build the graph and visualise\"\"\"\ngraph_builder = StateGraph(SearchState)\ngraph_builder.add_node(\"chatbot\", chatbot_with_tools) # Add the nodes, including the new tool_node.\ngraph_builder.add_node(\"human\", human_node)\ngraph_builder.add_node(\"tools\", tool_node)\ngraph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools) # Chatbot may go to tools, or human.\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node) # Human may go back to chatbot, or exit.\ngraph_builder.add_edge(\"tools\", \"chatbot\") # Tools always route back to chat afterwards.\ngraph_builder.add_edge(START, \"chatbot\")\ngraph_with_jobs = graph_builder.compile()\nImage(graph_with_jobs.get_graph().draw_mermaid_png()) # Visualise chat graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:26.458274Z","iopub.execute_input":"2025-04-20T15:43:26.458662Z","iopub.status.idle":"2025-04-20T15:43:26.605954Z","shell.execute_reply.started":"2025-04-20T15:43:26.458625Z","shell.execute_reply":"2025-04-20T15:43:26.604917Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"image/png":"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\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"---\n\n### üöÄ Executing the Chatbot with Configurations\n\nTo ensure smooth navigation across potentially **longer conversations**, we adjust the recursion limit. The default recursion limit for traversing nodes is **25**, but we can increase it to **100** for more extended interactions. This change allows the chatbot to handle deeper conversations without running into recursion depth errors.\n\nNext, we **execute the graph** to kick off the interaction:\n- The chatbot will run indefinitely until the user decides to exit by typing `q`, `quit`, or another exit phrase.\n- The system will continue running and processing messages through the defined flow, invoking the appropriate tools and nodes as needed.\n\nThis sets the chatbot into motion, ready to engage with the user!\n\n---\n","metadata":{}},{"cell_type":"code","source":"config = {\"recursion_limit\": 100} # default recursion limit for traversing nodes is 25 - setting it higher allows for longer chat\n# Loop forever, unless you input `q`, `quit` or one of the other exit terms defined in `human_node`.\nstate = graph_with_jobs.invoke({\"messages\": []}, config) # Execute the graph:","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:43:26.607172Z","iopub.execute_input":"2025-04-20T15:43:26.607720Z","iopub.status.idle":"2025-04-20T15:51:54.814266Z","shell.execute_reply.started":"2025-04-20T15:43:26.607691Z","shell.execute_reply":"2025-04-20T15:51:54.813228Z"}},"outputs":[{"name":"stdout","text":"Model: Welcome ! I am CarCou your virtual Career Counsellor. I am here to help you unlock your potentials. Are you here today : i) for a job hunt ii)to improve your current prospects eg. salary or change of position ? iii) Please Type `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  job hunt\n"},{"name":"stdout","text":"Model: Great! Let's start by getting to know you better.\n\n1.  What is your name?\n2.  Type `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Shami\n"},{"name":"stdout","text":"Model: Hello Shami, nice to meet you.\n\n1.  What degrees do you currently hold?\n2.  Type `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Master's in nlp engineering\n"},{"name":"stdout","text":"Model: Okay, Shami. An NLP Engineering degree is a great start.\n\n1.  What specific sectors or industries are you most interested in? (e.g., tech, finance, healthcare, etc.)\n2.  Type `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  healthcare\n"},{"name":"stdout","text":"Model: Alright, Shami. Healthcare is a very important sector.\n\n1.  What is your experience level? Are you a beginner (entering the job market), experienced (looking for a change), or established (looking to further career prospects)?\n2.  Type `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  beginner\n"},{"name":"stdout","text":"Model: Okay Shami, so just to confirm, you are Shami, you have a Master's in NLP Engineering, you're interested in the healthcare sector, and you're a beginner in the job market. Is that correct?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  yes\n"},{"name":"stdout","text":"Model: My apologies, Shami. There seems to be a technical issue with storing the jobs at the moment. However, I can still suggest them to you.\n\nBased on your background, here are three jobs that might be a good fit for you:\n\n1.  NLP Engineer in Healthcare\n2.  Data Scientist (Healthcare Focus)\n3.  Machine Learning Engineer (Healthcare)\n\nWhich of these options is your favourite?\n\nAlso, would you like help with a tailored resume?\n\nType `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  NLP Engineer in Healthcare\n"},{"name":"stdout","text":"Model: Great choice, Shami! An NLP Engineer role in healthcare can be very rewarding.\n\nWould you like me to help you create a tailored resume for this position?\n\nType `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  yes\n"},{"name":"stdout","text":"Model: Okay Shami, let's get started on your resume. Based on our conversation, here's a draft. Let me know if you'd like any changes.\n\n```markdown\n**Shami**\n[Your Phone Number] | [Your Email Address] | [Your LinkedIn Profile (Optional)]\n\n**Summary**\n\nHighly motivated and skilled NLP Engineer with a Master's degree, eager to apply expertise in natural language processing to improve healthcare outcomes. Passionate about leveraging machine learning to solve real-world problems and contribute to a data-driven healthcare environment.\n\n**Education**\n\n*   **Master of Science in NLP Engineering**\n    [University Name], [Graduation Year]\n\n**Skills**\n\n*   Natural Language Processing (NLP)\n*   Machine Learning\n*   Python\n*   [Add other relevant skills e.g., TensorFlow, PyTorch, data analysis, etc.]\n\n**Projects**\n\n*   [Project Name]: [Brief description of a relevant NLP project, highlighting your contributions and the results. If you don't have specific healthcare projects, focus on NLP projects that demonstrate your skills.]\n\n**Experience**\n\n*   [If you have any relevant internships or work experience, list them here. Even if it's not directly healthcare-related, highlight transferable skills.]\n\n```\n\nDo you need help with a cover letter?\n\nType `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  yes\n"},{"name":"stdout","text":"Model: Okay Shami, to create a cover letter, I need a bit more information. Please provide:\n\n1.  Your surname\n2.  Your full address\n\nType `q` to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  1. THIRION SEN 2. CORMEILLES-EN-PARISIS FRANCE \n"},{"name":"stdout","text":"Model: Okay Shami, thank you for the information. Here is a draft cover letter for you.\n\n```markdown\n[Your Full Name (Shami Thirion Sen)]\n[Your Address (CORMEILLES-EN-PARISIS FRANCE)]\n[Your Email Address]\n[Your Phone Number]\n[Date]\n\n[Hiring Manager Name (If you know it, otherwise use title)]\n[Hiring Manager Title]\n[Company Name]\n[Company Address]\n\nDear [Mr./Ms./Mx. Hiring Manager Last Name, or \"Hiring Team\"],\n\nI am writing to express my keen interest in the NLP Engineer position at [Company Name], as advertised on [Platform where you saw the advertisement]. As a recent graduate with a Master's degree in NLP Engineering and a strong interest in the healthcare sector, I am confident that my skills and passion align perfectly with your requirements.\n\nDuring my studies, I developed a strong foundation in natural language processing, machine learning, and data analysis. [Mention a specific project or skill that is relevant to the job description and demonstrates your abilities]. I am eager to apply my expertise to contribute to [Company Name]'s mission of [Mention something specific about the company's mission or goals that resonates with you].\n\nI am a highly motivated and quick learner with a strong work ethic and a collaborative spirit. I am confident that I can quickly integrate into your team and make a significant contribution to your projects.\n\nThank you for your time and consideration. I have attached my resume for your review and welcome the opportunity to discuss my qualifications further in an interview.\n\nSincerely,\n[Your Full Name (Shami Thirion Sen)]\n```\n\nThank you for consulting with me today. Please continue down the page to get more valuable information.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  QUIT\n"},{"name":"stdout","text":"Model: Thank you for consulting with me today, Shami. I wish you the best in your job search.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  q\n"}],"execution_count":10},{"cell_type":"markdown","source":"### üåê Search Grounding & Job Query with Grounding\n\nTo make **CarCou** even more powerful, we enable **search grounding**, allowing the chatbot to perform real-time internet searches to enhance the responses. With this functionality, the bot can:\n- Fetch **recent job postings** based on the user's provided job title and location\n- Retrieve **helpful YouTube videos** for job interview preparation\n\n#### üß† Job Search Query with Grounding\n\nIn the **`job_query_with_grounding()`** function, we enable the chatbot to:\n- Ask the user for their **current city** (since geographical location can't be accessed directly in this notebook)\n- Search the internet for **5 most recent job postings** matching the job title and location specified by the user\n\nThis feature uses **Google Search** to gather relevant information and presents it in a structured JSON format.\n\n**Few-Shot Prompting Idea**:\nTo improve the performance of this feature, we can use few-shot prompting to guide the model. A few-shot example could look like this:\n\n- **Prompt**: \"Find the latest job postings for software engineers in New York. Provide the 5 most relevant postings.\"\n- **Response**: \"Here are the top 5 recent job postings for Software Engineers in New York...\" (followed by structured details like job titles, companies, and URLs)\n\nThis example would help the model understand the format and types of information to retrieve.\n\n---\n\n#### üé• Fetching Helpful Videos for Job Preparation\n\nWith **`get_links_with_grounding()`**, CarCou can search for **top 5 YouTube videos** that help with job interview preparation for a specific role. For example, if the user is looking for **software engineering jobs**, it will provide the most relevant videos to help them prepare.\n\nThe returned output consists of a list of **URLs and brief descriptions** of each video, making it easy for users to explore valuable resources.\n\n**Few-Shot Prompting Idea**:\nWhen asking the model to search for videos, we can guide it with examples to improve results. A few-shot example could be:\n\n- **Prompt**: \"Find the 5 most relevant YouTube videos to help someone prepare for a software engineer interview.\"\n- **Response**: \"[('https://youtube.com/video1', 'Video 1 description'), ('https://youtube.com/video2', 'Video 2 description'), ...]\"\n\nProviding a structure like this helps the model format its output consistently and focus on the most helpful resources.\n\n---\n\n#### üîç Extracting Video Links\n\nOnce the YouTube video data is retrieved, we use **`parse_video_links()`** to:\n- Extract and **format** the video URLs and descriptions from the returned string.\n- Present them in an easy-to-read list, so users can quickly access relevant resources.\n\nThis step ensures that the chatbot's responses are not only intelligent but **actionable**, providing users with links to videos that can enhance their preparation for their desired roles.\n\nThis helps the model understand the correct way to present the extracted data for easy user consumption.\n\n---\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Image, Markdown\nimport re\nfrom urllib.parse import urlparse\n\n\n# Search grounding enabled.\nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature = 0.0,\n)\n\ndef job_query_with_grounding(job):\n    \"\"\"\n    Gets 5 most jobs posted on the internet based on the job title and the location provided\n    \"\"\"\n    # Ideally we should access the geographical location, but we cannot do on this notebook,so we'll ask the user\n    country = input(\"Please the current city where you are looking for a job:\")\n    response = client.models.generate_content(\n        model='gemini-2.0-flash',\n        contents=\"Search the 5 most recent job and their links offers posted on the internet for \" + job + \"format the answer in a json format located in \" + country,\n        config=config_with_search,\n    )\n    return response.text\n    \n\ndef get_links_with_grounding(job):\n    \"\"\" Get the  5 most relevant videos that can help with this particual job preparation\"\"\"\n    response = client.models.generate_content(\n        model='gemini-2.0-flash',\n       contents='Find the top 5 most relevant YouTube videos to help someone prepare for a job interview' + job + '. Return only a Python list of the video URLs and brief description composing of 5 sentences in a tuple form for each video. For example, if the job is for a software engineer, the output should look like this: [(\"https://www.youtube.com/watch?v=abcdefg123\", video description), (\"https://www.youtube.com/watch?v=hijklmn456\", video description), (\"https://www.youtube.com/watch?v=opqrstu789\", video description), (\"https://www.youtube.com/watch?v=vwxyz01234\", video description), (\"https://www.youtube.com/watch?v=uvwxyz56789\" , video description)].',            \n        config=config_with_search,\n    )\n    return response.text \n\n\n\ndef parse_video_links(video_str : str) -> list[str]:\n    \"\"\" Extract the video links : ideally generated as a string format containing a python list of links\"\"\"\n    video_links_and_description = []\n    code_block_pattern = r\"```python\\s*\\[(.*?)\\]\\s*```\"\n    code_block_match = re.search(code_block_pattern, video_str, re.DOTALL)\n    if code_block_match:\n        code_content = code_block_match.group(1)\n        pattern = r'\\(\"([^\"]+)\",\\s*\"([^\"]+)\"\\)'\n        matches = re.findall(pattern, code_content)\n        for i, (url, description) in enumerate(matches, 1):\n            video_links_and_description.append((url,description))\n        return video_links_and_description     \n    else:\n        print(\"No YouTube links found in code block.\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:51:54.815358Z","iopub.execute_input":"2025-04-20T15:51:54.815697Z","iopub.status.idle":"2025-04-20T15:51:54.825141Z","shell.execute_reply.started":"2025-04-20T15:51:54.815665Z","shell.execute_reply":"2025-04-20T15:51:54.824351Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"---\n### Retrieval-Augmented Generation (RAG)\n\n#### üß† Using Embeddings for **Vector Database with Chroma** (RAG)\n\nIn order to create a more **intelligent search experience**, we use **embeddings** to represent documents and queries as high-dimensional vectors. These embeddings are then stored in a **vector database** for fast retrieval based on similarity, enabling the **Retrieval-Augmented Generation (RAG)** method.\n\n#### üîè Gemini Embedding Function\n\nWe define the **`GeminiEmbeddingFunction`** class, which helps generate embeddings for both documents and queries:\n- If we're working with documents, it prepares them for **retrieval** and stores them in the vector database.\n- For queries, it allows us to search for the most **relevant document** in the database based on similarity.\n\nThe **`@retry` decorator** is used to ensure that when the API quota is hit (e.g., 429 or 503 errors), the request will be retried automatically, ensuring smoother operations.\n\n**RAG (Retrieval-Augmented Generation)**: This approach allows the system to **retrieve** relevant documents (using embeddings) and **augment** the generative model's responses with the retrieved content, making the conversation more informative and contextually relevant.\n\n---\n\n#### üóÇÔ∏è Adding Documents to the Vector Database\n\nThe function **`add_to_vector_database()`** accepts a list of documents and:\n- Generates embeddings for each document.\n- Stores these embeddings in the **Chroma vector database**.\n\nThis ensures that the documents are represented in a high-dimensional vector space, allowing for fast and efficient similarity-based retrieval later on.\n\n---\n\n#### üîç Retrieving Information from the Database\n\nThe function **`retrieve_database_item()`** allows us to:\n- Generate embeddings for the user‚Äôs **query**.\n- Search the **Chroma database** to find the most relevant document based on the query.\n\nIt retrieves the document ID of the most relevant result, making it easy for the chatbot to return targeted content.\n\n---\n\nWith **RAG**, the chatbot combines the **retrieved documents** from the vector database with its **generative capabilities**, improving the relevance and quality of the responses.\n\n---\n\nThis setup ensures that **CarCou** can efficiently store, retrieve, and process documents based on semantic similarity, and generate responses that are **contextually enriched** with real-time data from the vector database.\n\n---\n","metadata":{}},{"cell_type":"code","source":"import chromadb\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\nfrom google.genai import types\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503}) # # Define a helper to retry when per-minute quota is reached.\n\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\", # model used\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]\n\ndef add_to_vector_database(documents):\n    \"\"\"And a list of documents list[str] to the vectordatabase\"\"\"\n    DB_NAME = \"googlecardb\"\n    embed_fn = GeminiEmbeddingFunction()\n    embed_fn.document_mode = True # embed mode\n    chroma_client = chromadb.Client()\n    db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n    db.add(documents=documents, ids=[str(i) for i in range(len(documents))])\n\n    return db\n\n\ndef retrieve_database_item(query, db):\n    \"\"\" Retreives the best result corresponding to the user query\"\"\"\n    embed_fn = GeminiEmbeddingFunction()  # Switch to query mode when generating embeddings.\n    embed_fn.document_mode = False\n    result = db.query(query_texts=[query], n_results=1) # Search the Chroma DB using the specified query.\n    result_id = int(result['ids'][0][0])\n    \n    return result_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:51:54.826264Z","iopub.execute_input":"2025-04-20T15:51:54.826591Z","iopub.status.idle":"2025-04-20T15:51:55.447153Z","shell.execute_reply.started":"2025-04-20T15:51:54.826560Z","shell.execute_reply":"2025-04-20T15:51:55.446086Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### üìù Evaluating AI-Generated Summaries with **LLM as the Judge**\n\nIn this section, we evaluate the quality of AI-generated summaries using a **structured evaluation method**. The evaluation checks how well the summary adheres to the task instructions, its groundedness (staying true to the input), conciseness, and fluency. The **LLM** acts as the **judge** to ensure that the generated summaries meet the highest standards. ü§ñ\n\n#### üßë‚Äçüè´ Summary Evaluation Process\n\nWe define an **evaluation prompt** where the AI (acting as the judge) is tasked with assessing a generated summary according to several **criteria**:\n\n- **Instruction Following**: Does the response adhere to the summarization task‚Äôs requirements, including length constraints?\n- **Groundedness**: Does the response stay true to the provided context without adding outside information?\n- **Conciseness**: Is the summary brief but still informative?\n- **Fluency**: Is the response well-structured and easy to read?\n\n#### üéØ Rating Rubric\n\n- **5**: (Very good) - Excellent adherence to instructions, concise, grounded, and fluent.\n- **4**: (Good) - Minor issues, but the response still follows instructions and remains grounded and fluent.\n- **3**: (Okay) - Response mostly follows instructions, but lacks conciseness or fluency.\n- **2**: (Bad) - Response is grounded but doesn't follow instructions correctly.\n- **1**: (Very bad) - The summary is not grounded in the provided context.\n\n---\n\n#### üõ†Ô∏è Code Implementation\n\nIn the `eval_summary()` function, we evaluate AI-generated responses by:\n\n1. **Creating a chat session**: We use the **Gemini model** (or another available model) to evaluate the quality of the summary, with the LLM acting as the judge in the process.\n2. **Constructing the evaluation prompt**: The input prompt and AI-generated response are embedded into a structured evaluation prompt for the LLM to review.\n3. **Parsing the Evaluation**: The LLM assesses the summary using the **evaluation rubric**, then returns the evaluation as a structured score (`SummaryRating`).\n\n---\n\nThis setup allows for a **detailed, step-by-step evaluation** of AI-generated summaries, providing insights into their quality based on predefined criteria. The LLM's judgment ensures consistency and objectivity in the evaluation process.\n\n---\n","metadata":{}},{"cell_type":"code","source":"## Evaluate Video Summary\nimport enum\n\n# Define the evaluation prompt\nSUMMARY_PROMPT = \"\"\"\\\n# Instruction\nYou are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models.\nWe will provide you with the user input and an AI-generated responses.\nYou should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\nYou will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step-by-step explanations for your rating, and only choose ratings from the Rating Rubric.\n\n# Evaluation\n## Metric Definition\nYou will be assessing summarization quality, which measures the overall ability to summarize text. Pay special attention to length constraints, such as in X words or in Y sentences. The instruction for performing a summarization task and the context to be summarized are provided in the user prompt. The response should be shorter than the text in the context. The response should not contain information that is not present in the context.\n\n## Criteria\nInstruction following: The response demonstrates a clear understanding of the summarization task instructions, satisfying all of the instruction's requirements.\nGroundedness: The response contains information included only in the context. The response does not reference any outside information.\nConciseness: The response summarizes the relevant details in the original text without a significant loss in key information without being too verbose or terse.\nFluency: The response is well-organized and easy to read.\n\n## Rating Rubric\n5: (Very good). The summary follows instructions, is grounded, is concise, and fluent.\n4: (Good). The summary follows instructions, is grounded, concise, and fluent.\n3: (Ok). The summary mostly follows instructions, is grounded, but is not very concise and is not fluent.\n2: (Bad). The summary is grounded, but does not follow the instructions.\n1: (Very bad). The summary is not grounded.\n\n## Evaluation Steps\nSTEP 1: Assess the response in aspects of instruction following, groundedness, conciseness, and verbosity according to the criteria.\nSTEP 2: Score based on the rubric.\n\n# User Inputs and AI-generated Response\n## User Inputs\n\n### Prompt\n{prompt}\n\n## AI-generated Response\n{response}\n\"\"\"\n\n# Define a structured enum class to capture the result.\nclass SummaryRating(enum.Enum):\n  VERY_GOOD = '5'\n  GOOD = '4'\n  OK = '3'\n  BAD = '2'\n  VERY_BAD = '1'\n\n\ndef eval_summary(prompt, ai_response):\n  \"\"\"Evaluate the generated summary against the prompt used.\"\"\"\n\n  chat = client.chats.create(model='gemini-1.5-flash')\n\n  # Generate the full text response.\n  response = chat.send_message(\n      message=SUMMARY_PROMPT.format(prompt=prompt, response=ai_response)\n  )\n  verbose_eval = response.text\n\n  # Coerce into the desired structure.\n  structured_output_config = types.GenerateContentConfig(\n      response_mime_type=\"text/x.enum\",\n      response_schema=SummaryRating,\n  )\n  response = chat.send_message(\n      message=\"Convert the final score.\",\n      config=structured_output_config,\n  )\n  structured_eval = response.parsed.value # number\n    \n  return verbose_eval, structured_eval\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:51:55.450157Z","iopub.execute_input":"2025-04-20T15:51:55.450439Z","iopub.status.idle":"2025-04-20T15:51:55.458739Z","shell.execute_reply.started":"2025-04-20T15:51:55.450419Z","shell.execute_reply":"2025-04-20T15:51:55.457597Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"---\n\n### üé• YouTube Video Transcription and Summarization\n\nIn this section, we focus on extracting the **transcript** from a YouTube video and generating a **concise summary** based on the transcription. The process ensures that summaries are **accurate** and adhere to a **specified length** (500 words, in this case).\n\n#### üîç Extracting YouTube Transcription\n\nWe begin by extracting the **video ID** from the provided YouTube video URL. This step is important for interfacing with the **YouTube Transcript API** to retrieve the video‚Äôs transcript.\n\n1. **Video ID Extraction**: Depending on the URL format (e.g., `youtube.com` or `youtu.be`), the function extracts the video ID.\n2. **Transcript Retrieval**: Using the extracted video ID, we call the **YouTube Transcript API** to fetch the transcription of the video.\n\n\n#### üìù Video Summary Generation\n\nOnce we have the transcript, we generate a concise **summary** using the **Gemini 2.0 Flash model**. This involves submitting the transcript to the model for summarization based on the given prompt.\n\n1. **Prompt Setup**: A custom prompt is constructed by appending the video transcript to the instruction text.\n2. **AI Summary Generation**: The model generates a summary of the video transcript.\n3. **Evaluation**: The summary is evaluated based on predefined criteria (using the `eval_summary()` function). Only summaries with a rating of **4** or higher are returned; otherwise, the process is repeated.\n\n\n#### üõ†Ô∏è Process Overview\n\n1. **Transcription Extraction**: The video transcript is retrieved from YouTube using its API.\n2. **Prompt-Based Summarization**: The model generates a concise summary based on the entire transcript.\n3. **Summary Evaluation**: We ensure that only quality summaries (those rated 4 or higher) are kept. In case the summary doesn't meet the quality threshold, the process is retried.\n\nThis method enables accurate and reliable summaries of YouTube videos, ensuring that the summaries are **concise**, **relevant**, and **well-structured**.\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"!pip install youtube_transcript_api\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom pprint import pprint\nfrom urllib.parse import urlparse, parse_qs\n\n\ndef get_video_transcription(url):\n    \"\"\"Function to extract video ID from a full URL\"\"\"    \n    parsed_url = urlparse(url)\n    if 'youtube' in parsed_url.netloc:\n        video_id = parse_qs(parsed_url.query)['v'][0]\n    elif 'youtu.be' in parsed_url.netloc:\n        video_id = parsed_url.path[1:]\n    else:\n        video_id = None\n\n    if video_id is not None:\n        transcript = YouTubeTranscriptApi.get_transcript(video_id)    \n        full_text = ' '.join([entry['text'] for entry in transcript])\n    else:\n        full_text = None\n    return full_text\n    \n    \n# Summarize videos\ndef get_video_summary(video_url:str, prompt_text=\"\") -> str:\n    \"\"\"\n    Takes as input youtube video summary returns it's short summary.\n\n    Args:\n    str: Video transcript\n\n    Returns:\n    Video summary, as string\n    \"\"\"\n    # Get video transcript \n    video_transcript = get_video_transcription(video_url)\n    if video_transcript:\n        prompt_text = prompt_text + \"Please summarize in 500 words the following text in the most natural manner :\" + video_transcript    \n        response = client.models.generate_content(\n            model='gemini-2.0-flash',\n            contents=prompt_text,\n            config=config_with_search,\n        )\n        ## Evaluate Response before returning, return only if equal to or above 4 (good or very good)\n        verbose_eval, structured_eval = eval_summary(prompt_text, response.text)\n        # print(\"Verbose Eval = \",verbose_eval) # Verbal description of the generation\n        print(\"Structured Eval = \" , structured_eval , \"\\n\\n\")\n        if int(structured_eval) >= 4:\n            return response.text\n        else:\n            # else we're going to regenerate the summary \n            get_video_summary(video_url, \"Generate as accurately as possible the following instruction.\")\n    else:\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:51:55.459744Z","iopub.execute_input":"2025-04-20T15:51:55.460098Z","iopub.status.idle":"2025-04-20T15:51:59.959200Z","shell.execute_reply.started":"2025-04-20T15:51:55.460074Z","shell.execute_reply":"2025-04-20T15:51:59.958093Z"}},"outputs":[{"name":"stdout","text":"Collecting youtube_transcript_api\n  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\nDownloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: youtube_transcript_api\nSuccessfully installed youtube_transcript_api-1.0.3\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"üéâ **Now that we have all the ingredients, let‚Äôs put it all together!** üéâ\n\nIn this process, we‚Äôre going to guide you through finding the perfect job, preparing for your interview, and helping you succeed at every step. Let‚Äôs break it down:\n\n### 1Ô∏è‚É£ **Choose Your Preferred Job** üßë‚Äçüíº  \nFirst, I'll ask you about your **preferred job**. Don‚Äôt worry if you‚Äôre unsure! You can pick from a list of suggestions, or if you're still not sure, I‚Äôll help you make the best choice. üòå\n\n### 2Ô∏è‚É£ **Get Job Suggestions** üíº  \nOnce we know your preferred job, I‚Äôll search for **the best job openings** related to that career. You'll get a list of relevant opportunities tailored to your interest. üéØ\n\n### 3Ô∏è‚É£ **Prepare with Helpful Resources** üé•  \nJob found? Great! Now, let‚Äôs make sure you're **interview-ready**. I‚Äôll suggest the most relevant **YouTube videos** to help you prepare. üìπ These videos are specially picked to help you shine during interviews!\n\n### 4Ô∏è‚É£ **Select the Best Video & Get a Summary** üîç  \nGot a lot of content? Don‚Äôt worry, I‚Äôll help you **pick the best video** for your professional aspirations! üåü Once selected, if you need a **summary** to save time, I‚Äôll provide that for you too. üìù\n\n### 5Ô∏è‚É£ **Wrapping It Up** üéØ  \nYou‚Äôll have control over each step ‚Äì whether it‚Äôs asking for more help or moving on to the next phase. I‚Äôm here to assist whenever you need me! üòä\n\nüí¨ Ready to dive in? Let‚Äôs start your journey toward that dream job! üöÄ\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import Markdown, display\nimport random, string\n\ntry:\n    job_list  # Check if it exists\nexcept NameError:\n    preferred_job = input(\"Please enter the job you're interested in: \").strip() # Else get user input\nelse:\n    preferred_job = input(\"Tell me, amongst \" + \", \".join(job_list) + \", which is your favourite job? \").strip()\n    if not preferred_job:\n        preferred_job = random.choice(job_list)    \n    elif preferred_job not in job_list:\n        preferred_job = preferred_job.strip().translate(str.maketrans('', '', string.punctuation))\n        matches = [job for job in job_list if preferred_job.lower() in job.lower()]\n        preferred_job = matches[0]       \nprint(\"Thank you, I will find some job suggestions for \", preferred_job, \" options.\")\n\ntry:\n    rc = job_query_with_grounding(preferred_job) # get grounded job postings\n    print(\"Here are a few job suggestions based on your interest:\")\n    display(Markdown(rc))\n    assistance = input(\"Would you like further assistance with your job search? \\nI can help you find content online to prepare for your interview. (yes/no): \").strip().lower()\n    if assistance in {\"yes\", \"sure\", \"yup\", \"why not\"}:\n        video_links = get_links_with_grounding(preferred_job) # get relevant video links to prepare for the job\n        videos = parse_video_links(video_links) # list of all the videos [(video description, video_link)]\n        if videos is not None:\n            print(\"Here are a few videos in order to help you prepare.\")\n            for video in videos:\n                print(\"Video description: \", video[1])\n                display(Markdown(f\"[Video Link]({video[0]})\"))# , video[0], \"\\n\")\n            ## vector db\n            descriptions = [item[1] for item in videos]\n            db = add_to_vector_database(descriptions)\n        \n            \n            # RAG -> pick best -> transcribe and summarize -> evaluate summary\n            pick_video = input(print(\"Wow, that's lot of content! Would you like me to help you further?\"))\n            if pick_video in {\"Sure\", \"yes\", \"yeah\", \"go ahead\"}:\n                query = input(\"Ok, describe in a couple of sentences what your professional aspirations are, and I will find a video that's the most suitable for you.\") \n            else:\n                print(\"All the very best for your search. Remember CarCou is here for you. See ya!\")\n                # exit()\n            # retrieve the most suitable video \n            best_matching_id = retrieve_database_item(query, db)\n            display(Markdown(f\"\\nAccording to your search the most helpful video is: [Video Link]({videos[best_matching_id][0]})\\n, {videos[best_matching_id][1]}\"))\n            # print(\"\\nAccording to your search the most helpful video is: \", videos[best_matching_id][0], \"\\n\", videos[best_matching_id][1], \"\\n\")\n            summarize = (input(\"Would you like a summary of the video (yes/no)?\"))\n            if summarize in {\"Sure\", \"yes\", \"yeah\", \"go ahead\"}:\n                video_summary = get_video_summary(videos[best_matching_id][0])\n                if video_summary is not None:\n                    print(\"Here is a short summary for you : \\n\")\n                    display(Markdown(video_summary))\n                    print(\"Good luck with your endeavours! Reach out to me anytime. See you!\")\n                else:\n                    print(\"Sorry, cannot get video transcription right now. My apologies.\")\n                    exit()\n        else:\n            print(\"Sorry, currently I cannot get further links. Please try again later.\")            \n    else:\n        print(\"Awesome, wish you luck!\")\n            # exit()\n\nexcept Exception as e:\n    print(\"Sorry, something went wrong while fetching info:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:51:59.960452Z","iopub.execute_input":"2025-04-20T15:51:59.960790Z","iopub.status.idle":"2025-04-20T15:53:17.171184Z","shell.execute_reply.started":"2025-04-20T15:51:59.960758Z","shell.execute_reply":"2025-04-20T15:53:17.170126Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Tell me, amongst NLP Engineer in Healthcare, Data Scientist (Healthcare Focus), Machine Learning Engineer (Healthcare), which is your favourite job?  Data Scientist (Healthcare Focus)\n"},{"name":"stdout","text":"Thank you, I will find some job suggestions for  Data Scientist (Healthcare Focus)  options.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Please the current city where you are looking for a job: paris\n"},{"name":"stdout","text":"Here are a few job suggestions based on your interest:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```json\n[\n  {\n    \"title\": \"Health Data Scientist\",\n    \"company\": \"Indeed\",\n    \"location\": \"Paris (75)\",\n    \"date_posted\": \"2025-04-19\",\n    \"link\": \"https://www.indeed.com/jobs?q=Health+Data+Scientist&l=Paris+%2875%29\"\n  },\n  {\n    \"title\": \"Senior Data Scientist Deep Learning\",\n    \"company\": \"Sanofi\",\n    \"location\": \"Paris (75)\",\n    \"date_posted\": \"2025-04-16\",\n    \"link\": \"https://www.indeed.com/jobs?q=Data+Science+Health&l=Paris+%2875%29\"\n  },\n   {\n    \"title\": \"Data Scientist\",\n    \"company\": \"Sanofi\",\n    \"location\": \"Paris, France\",\n    \"date_posted\": \"2025-04-09\",\n    \"link\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAK-GnbR9g-zY0TCRWf8vKOIZzih4zA6nEISsiXn8MvpPEde3evA3hSIsL_XZ8NF1calsRNLXIsYeuCPO5a_dpeVIQGnYAv3a1626ba1CLHerPFNXEMIN7d6mA2SBEUOPzahI8RbkXjuBMqWKQlZ1MVJP9QwamLpFRu5DTZx5w==\"\n  },\n  {\n    \"title\": \"Real-World Evidence Data Scientist\",\n    \"company\": \"Sanofi\",\n    \"location\": \"Paris, France\",\n    \"date_posted\": \"Unknown\",\n    \"link\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAIzhhlii_Di-178mExTUSC2xGN4fNYx4y1Q7Y_Yzd1MMlP4Fvbm36w99dNUDrs1fKjinwaXjkDegvFjj26OJza55aeFzU0ZPpZgadAJKiytw3GE_X4drHIpcHiRBbCmxKjY6RRyFs3cEfnYL9mB3QDvO3X07j1CB_mK4WV5ZM0FoCt99tbauDr_rl6Xf70Zd0q9SiU=\"\n  },\n  {\n    \"title\": \"Data Scientist Exp√©riment√© - H/F // Data Lab RH Groupe - BNP Paribas\",\n    \"company\": \"BNP Paribas\",\n    \"location\": \"Paris, France\",\n    \"date_posted\": \"14 hours ago\",\n    \"link\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AWQVqAKRRnessCGrkajCfP0cJXEhk11P3t701ClP5WHc7boxVpFtO8k0Up3itQuCiBBgFxunlDmtKf9JYcbNakE8lRtUCt1Ej24Z7E94PXZi89DuqNtEmKSFF092cM6evscXNxHVs9E_9XLPuZCQjCMIWd4j_KIon3L1-puTtwt-Ey4CLw==\"\n  }\n]\n```\nPlease note:\n\n*   The date posted information is relative (\"x hours/days ago\") and might not be precise.\n*   I have included job postings that mention \"Data Scientist\" and are located in \"Paris\" or the \"Paris area\" with a focus on healthcare where possible.\n*   Some entries lack a specific date but are included based on relevance and location.\n*   The links provided may direct to a search results page rather than a specific job posting in some instances.\n*   This information is current as of April 20, 2025.\n"},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Would you like further assistance with your job search? \nI can help you find content online to prepare for your interview. (yes/no):  yes\n"},{"name":"stdout","text":"Here are a few videos in order to help you prepare.\nVideo description:  This video provides six important tips to pass data science interviews. It emphasizes understanding the role and studying the company to align your skills and experiences with their needs. The STAR method (Situation, Task, Action, Result) is recommended for answering questions effectively by providing structured and detailed responses. The video also highlights the importance of being animated and enthusiastic during the interview to demonstrate genuine interest and cultural fit. Additionally, it advises preparing for technical questions by reviewing data science basics and looking for consistent questions asked by the company. Finally, the video suggests planning key examples from your past experiences to showcase your skills and accomplishments.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"[Video Link](https://www.youtube.com/watch?v=3zjjEttiHMY&t=199s)"},"metadata":{}},{"name":"stdout","text":"Video description:  This YouTube video presents data science interview questions and answers asked at Cognizant. It emphasizes the importance of being well-prepared for data science interviews to answer questions structurally. The video covers questions related to precision and recall, which are evaluation metrics for classification models in machine learning. It explains how to calculate precision and recall using a confusion matrix with examples related to predicting whether a person has cancer. The video also discusses AB testing, PCA, and multicollinearity, providing detailed explanations and examples for each concept.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"[Video Link](https://www.youtube.com/watch?v=DaK-AAXRaIQ?si=5u87thhUuyFKFwrk)"},"metadata":{}},{"name":"stdout","text":"Video description:  This video provides three tips for acing a data scientist interview. First, it emphasizes communicating with the recruiter to understand the interview's scope, including whether it will be a coding, behavioral, product case, or machine learning interview. Second, it advises researching the company to learn about their mission, values, products, services, and culture. This research demonstrates genuine interest and helps answer questions confidently. Third, the video recommends reviewing your resume to present past experiences and projects with ease, ensuring you can answer questions about your roles and responsibilities effectively.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"[Video Link](https://www.youtube.com/watch?v=TU0Ce5XQGns?si=xjUhfromZDN_noDV)"},"metadata":{}},{"name":"stdout","text":"Video description:  This video features a full-length data science interview to demonstrate what a data science interview is like. It is useful for those applying for data science or data analytics roles and want to see a strong interview example. The video covers building a dataset for training/testing purposes, feature vectorization, and model implementation details. It suggests pausing after each question to consider how you would answer. The interview includes introductory behavioral questions, a task overview related to a social media platform bot issue, and discussions on feature investigation and classification model implementation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"[Video Link](https://www.youtube.com/watch?v=M5atYaGCFEY?si=Gvr0nSTv60PrCe7w)"},"metadata":{}},{"name":"stdout","text":"Video description:  This video features a conversation with Dr. Adebayo, who shares his journey from medicine to health data science. He discusses the difficulties and benefits of switching from medicine to data science. He emphasizes the importance of understanding the healthcare sector and the ability to interact with various stakeholders. Dr. Adebayo offers helpful guidance for anyone thinking about making the switch to a job in health data science, emphasizing the value of developing a solid foundation in the fundamentals, finding mentors and networking opportunities, and keeping up with the most recent advancements in the industry. He also highlights the high demand for data scientists in the health sector.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"[Video Link](https://www.youtube.com/watch?v=2jsPQrjo3XQ?si=gQV_NHPssmoDudSK)"},"metadata":{}},{"name":"stdout","text":"Wow, that's lot of content! Would you like me to help you further?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"None yes\nOk, describe in a couple of sentences what your professional aspirations are, and I will find a video that's the most suitable for you. how to prepare for an interview\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\nAccording to your search the most helpful video is: [Video Link](https://www.youtube.com/watch?v=TU0Ce5XQGns?si=xjUhfromZDN_noDV)\n, This video provides three tips for acing a data scientist interview. First, it emphasizes communicating with the recruiter to understand the interview's scope, including whether it will be a coding, behavioral, product case, or machine learning interview. Second, it advises researching the company to learn about their mission, values, products, services, and culture. This research demonstrates genuine interest and helps answer questions confidently. Third, the video recommends reviewing your resume to present past experiences and projects with ease, ensuring you can answer questions about your roles and responsibilities effectively."},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Would you like a summary of the video (yes/no)? yes\n"},{"name":"stdout","text":"Structured Eval =  5 \n\n\nHere is a short summary for you : \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"To get shortlisted for data science roles, it's crucial to have a strong portfolio of data science projects on your CV. Here's how to build one:\n\n**1. Take a Focused Approach:**\n\n*   **Experienced Professionals:** If you have industry experience (e.g., finance, automotive), build 2-3 projects related to that domain. Target data science roles within those specific industries.\n*   **Freshers:** Focus on popular data science domains like finance, automotive, or manufacturing. Create separate CVs, each highlighting 2-3 relevant projects for each domain.\n\n**2. Project Ideas by Domain:**\n\n*   **Finance:**\n    *   Credit card fraud detection.\n    *   Credit risk modeling (predicting loan defaults).\n    *   Investment banking: Risk prediction using news sentiment analysis to correlate with stock price movements.\n*   **Pharma/Healthcare:**\n    *   Heart failure risk prediction using health parameters.\n    *   Drug discovery clustering: Analyze patient reactions to new drugs using text data to identify symptom patterns.\n*   **Automotive/Manufacturing:**\n    *   Demand forecasting to optimize supply chain management.\n    *   Supply chain delay prediction.\n    *   Predictive maintenance: Use IoT sensor data to predict machine maintenance needs.\n*   **E-commerce/Telecom:**\n    *   Customer churn prediction.\n    *   Recommendation models.\n    *   Fraudulent transaction prediction.\n\n**3. Project Variety:**\n\nEven within a specific domain, aim for diversity in your project types. Include projects that involve:\n\n*   Classification models.\n*   Regression models.\n*   Clustering or text data analysis.\n\n**4. Resources:**\n\nUtilize available resources like open-source datasets and domain-specific project implementations to learn and build your projects.\n\n**5. Hands-on Implementation:**\n\nActively build the projects yourself. This ensures you can confidently answer questions about them during interviews.\n\nBy following these steps, you can create a compelling data science project portfolio that significantly increases your chances of landing interview calls.\n"},"metadata":{}},{"name":"stdout","text":"Good luck with your endeavours! Reach out to me anytime. See you!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## üéØ Conclusion: Empowering Job Search with AI\n\nThis project demonstrates how CarCou integrates real-time search grounding, retrieval-augmented generation (RAG), and few-shot prompting to become a powerful, personalized job assistant. By leveraging these techniques, CarCou is able to provide highly relevant, grounded, and dynamic responses that enhance the user experience. Here's a breakdown of the key takeaways:\n\n### üåê Real-Time Information Retrieval\nWith search grounding, CarCou can fetch the latest job postings and helpful video resources based on the user‚Äôs location and job preferences. This makes the chatbot dynamic and context-aware, providing up-to-date and relevant content at all times.\n\n### üîç Retrieval-Augmented Generation (RAG)\nUsing RAG, CarCou intelligently retrieves the most suitable resources by filtering through large amounts of data, ensuring that the responses are accurate and grounded in real-world information. This enables the assistant to provide reliable, actionable responses.\n\n### üßë‚Äçüíº Grounded Search: Personalized Job Assistance\nBy asking for the user‚Äôs city or job preferences, CarCou delivers personalized **real-time** job listings and resources that match the user‚Äôs needs. This personalized approach enhances the relevance of the assistant‚Äôs responses, making the experience more engaging and tailored to the individual.\n\n### üé• Summarization Capabilities\nCarCou goes beyond job listings by fetching relevant YouTube videos to help users prepare for job interviews. It even summarizes videos when needed, through transcription, giving users the right tools to succeed in their job search journey. This holistic approach ensures that users get both job opportunities and interview prep materials.\n\n### ü§ñ Few-Shot Prompting for Better Results\nWith few-shot prompting, CarCou understands the user‚Äôs needs more accurately and generates structured, contextually relevant responses. This technique enhances the assistant's ability to interpret user queries and deliver high-quality outputs.\n\n### üìù LLM as a Judge: Evaluation of AI-Generated Content \nBy integrating a structured evaluation mechanism, CarCou ensures that only high-quality content is provided to users. It assesses summaries based on instruction following, groundedness, conciseness, and fluency, ensuring the assistant delivers reliable and trustworthy responses.\n\n### üöÄ Scalability and Flexibility\nThe system‚Äôs architecture is scalable, allowing for the integration of new data sources such as additional job boards, interview prep resources, and more. This flexibility ensures that CarCou can evolve with the changing job market and continue to deliver value over time.\n\n### üí° Overall Impact\nBy combining retrieval capabilities, personalization, and evaluation techniques, CarCou provides a comprehensive solution for job seekers. The project showcases the potential for AI to assist users in their career journey by offering relevant, actionable, and dynamic responses. CarCou can be further extended to include additional features like salary insights, company reviews, and career advice, making it a one-stop solution for all job seekers.\n\nIn conclusion, this project highlights the power of AI to not only provide information but also offer personalized assistance and valuable insights. CarCou is a next-generation AI assistant, capable of empowering users in their job search journey and helping them succeed in today‚Äôs competitive job market. üåü","metadata":{}}]}